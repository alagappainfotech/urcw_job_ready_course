                     MODULE_9_EXERCISES_ANSWERS
import os
import csv
import json
import xml.etree.ElementTree as ET
import zipfile
import tarfile
import hashlib
import shutil
import time
from pathlib import Path
from typing import List, Dict, Any, Optional, Union
from collections import defaultdict
import tempfile
class FileOperations:
    """Basic file operations and utilities"""
    def __init__(self):
        self.temp_dir = tempfile.gettempdir()
    def read_text_file(self, filename: str, encoding: str = 'utf-8') -> str:
        """Read text file with error handling"""
        try:
            with open(filename, 'r', encoding=encoding) as file:
                return file.read()
        except FileNotFoundError:
            print(f"File {filename} not found")
            return ""
        except PermissionError:
            print(f"Permission denied to read {filename}")
            return ""
        except UnicodeDecodeError:
            print(f"Encoding error reading {filename}")
            return ""
    def write_text_file(self, filename: str, content: str, encoding: str = 'utf-8') -> bool:
        """Write text to file with error handling"""
        try:
            Path(filename).parent.mkdir(parents=True, exist_ok=True)
            
            with open(filename, 'w', encoding=encoding) as file:
                file.write(content)
            return True
        except PermissionError:
            print(f"Permission denied to write {filename}")
            return False
        except OSError as e:
            print(f"OS error writing {filename}: {e}")
            return False
    def append_to_file(self, filename: str, content: str, encoding: str = 'utf-8') -> bool:
        """Append content to file"""
        try:
            with open(filename, 'a', encoding=encoding) as file:
                file.write(content)
            return True
        except Exception as e:
            print(f"Error appending to {filename}: {e}")
            return False
     def read_lines(self, filename: str, encoding: str = 'utf-8') -> List[str]:
        """Read file line by line"""
        lines = []
        try:
            with open(filename, 'r', encoding=encoding) as file:
                for line in file:
                    lines.append(line.rstrip('\n'))
        except Exception as e:
            print(f"Error reading lines from {filename}: {e}")
        return lines
    def write_lines(self, filename: str, lines: List[str], encoding: str = 'utf-8') -> bool:
        """Write list of lines to file"""
        try:
            Path(filename).parent.mkdir(parents=True, exist_ok=True)
            
            with open(filename, 'w', encoding=encoding) as file:
                for line in lines:
                    file.write(line + '\n')
return True
        except Exception as e:
            print(f"Error writing lines to {filename}: {e}")
            return False
  def copy_file(self, source: str, destination: str) -> bool:
        """Copy file from source to destination"""
        try:
            Path(destination).parent.mkdir(parents=True, exist_ok=True)
            
            shutil.copy2(source, destination)
            return True
        except Exception as e:
            print(f"Error copying file: {e}")
            return False
    def move_file(self, source: str, destination: str) -> bool:
        """Move file from source to destination"""
        try:
            Path(destination).parent.mkdir(parents=True, exist_ok=True)
            
            shutil.move(source, destination)
            return True
        except Exception as e:
            print(f"Error moving file: {e}")
            return False
    def delete_file(self, filename: str) -> bool:
        """Delete file"""
        try:
            if Path(filename).exists():
                Path(filename).unlink()
                return True
            return False
        except Exception as e:
            print(f"Error deleting file {filename}: {e}")
            return False
class FileSystemManager:
    """Advanced file system operations using pathlib"""
    def __init__(self, base_path: str = "."):
        self.base_path = Path(base_path)
   def create_directory(self, dir_path: str) -> bool:
        """Create directory and parent directories if needed"""
        try:
            full_path = self.base_path / dir_path
            full_path.mkdir(parents=True, exist_ok=True)
            return True
        except Exception as e:
            print(f"Error creating directory: {e}")
            return False
    def delete_directory(self, dir_path: str) -> bool:
        """Delete directory and all contents"""
        try:
            full_path = self.base_path / dir_path
            if full_path.exists():
                shutil.rmtree(full_path)
            return True
        except Exception as e:
            print(f"Error deleting directory: {e}")
            return False
     def list_files(self, pattern: str = "*", recursive: bool = False) -> List[Path]:
        """List files matching pattern"""
        try:
            if recursive:
                return list(self.base_path.rglob(pattern))
            else:
                return list(self.base_path.glob(pattern))
        except Exception as e:
            print(f"Error listing files: {e}")
            return []
  def find_files_by_extension(self, extension: str) -> List[Path]:
        """Find all files with specific extension"""
        pattern = f"**/*.{extension}"
        return self.list_files(pattern, recursive=True)
     def get_file_info(self, file_path: str) -> Dict[str, Any]:
        """Get detailed file information"""
        try:
            full_path = self.base_path / file_path
            if not full_path.exists():
                return {}
             stat = full_path.stat()
            return {
                'name': full_path.name,
                'size': stat.st_size,
                'created': stat.st_ctime,
                'modified': stat.st_mtime,
                'is_file': full_path.is_file(),
                'is_dir': full_path.is_dir(),
                'extension': full_path.suffix,
                'parent': str(full_path.parent),
                'absolute_path': str(full_path.absolute())
            }
        except Exception as e:
            print(f"Error getting file info: {e}")
            return {}
    def search_files_by_content(self, search_term: str, file_extensions: List[str] = None) -> List[Path]:
        """Search for files containing specific content"""
        matching_files = []
        
        try:
            for file_path in self.list_files("**/*", recursive=True):
                if file_path.is_file():
                    if file_extensions and file_path.suffix not in file_extensions:
                        continue
                   try:
                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as file:
                            if search_term in file.read():
                                matching_files.append(file_path)
                    except (UnicodeDecodeError, PermissionError):
                        continue
        except Exception as e:
            print(f"Error searching files: {e}")
        return matching_files
 def get_directory_size(self, dir_path: str) -> int:
        """Calculate total size of directory"""
        total_size = 0
        try:
            full_path = self.base_path / dir_path
            for file_path in full_path.rglob("*"):
                if file_path.is_file():
                    total_size += file_path.stat().st_size
        except Exception as e:
            print(f"Error calculating directory size: {e}")
        return total_size
class CSVHandler:
    """CSV file reading and writing utilities"""
def read_csv(self, filename: str, delimiter: str = ',', encoding: str = 'utf-8') -> List[Dict[str, Any]]:
        """Read CSV file and return list of dictionaries"""
        data = []
        try:
            with open(filename, 'r', newline='', encoding=encoding) as file:
                reader = csv.DictReader(file, delimiter=delimiter)
                for row in reader:
                    data.append(dict(row))
        except Exception as e:
            print(f"Error reading CSV: {e}")
        return data
 def write_csv(self, filename: str, data: List[Dict[str, Any]], 
                  fieldnames: List[str] = None, encoding: str = 'utf-8') -> bool:
        """Write data to CSV file"""
        try:
            if not data:
                return False
           if fieldnames is None:
                fieldnames = list(data[0].keys())
        Path(filename).parent.mkdir(parents=True, exist_ok=True)
             with open(filename, 'w', newline='', encoding=encoding) as file:
               writer = csv.DictWriter(file, fieldnames=fieldnames)
                writer.writeheader()
                writer.writerows(data)
            return True
        except Exception as e:
            print(f"Error writing CSV: {e}")
            return False
   def append_csv(self, filename: str, data: List[Dict[str, Any]], 
                   fieldnames: List[str] = None, encoding: str = 'utf-8') -> bool:
        """Append data to existing CSV file"""
        try:
            if not data:
                return False
            if fieldnames is None:
                fieldnames = list(data[0].keys())
            file_exists = Path(filename).exists()
            with open(filename, 'a', newline='', encoding=encoding) as file:
                writer = csv.DictWriter(file, fieldnames=fieldnames)
                if not file_exists:
                    writer.writeheader()
                writer.writerows(data)
            return True
        except Exception as e:
            print(f"Error appending CSV: {e}")
            return False
  def filter_csv(self, filename: str, filter_func, output_filename: str = None) -> List[Dict[str, Any]]:
        """Filter CSV data based on function"""
        data = self.read_csv(filename)
        filtered_data = [row for row in data if filter_func(row)]
        if output_filename:
            self.write_csv(output_filename, filtered_data)
         return filtered_data
 def merge_csv_files(self, filenames: List[str], output_filename: str) -> bool:
        """Merge multiple CSV files"""
        try:
            all_data = []
            fieldnames = set()
            
            for filename in filenames:
                data = self.read_csv(filename)
                all_data.extend(data)
                if data:
                    fieldnames.update(data[0].keys())
             return self.write_csv(output_filename, all_data, list(fieldnames))
        except Exception as e:
            print(f"Error merging CSV files: {e}")
            return False
class JSONHandler:
    """JSON file reading and writing utilities"""
    def read_json(self, filename: str, encoding: str = 'utf-8') -> Union[dict, list, None]:
        """Read JSON file and return Python object"""
        try:
            with open(filename, 'r', encoding=encoding) as file:
                return json.load(file)
        except FileNotFoundError:
            print(f"File {filename} not found")
            return None
        except json.JSONDecodeError as e:
            print(f"JSON decode error: {e}")
            return None
        except Exception as e:
            print(f"Error reading JSON: {e}")
            return None
    def write_json(self, filename: str, data: Any, indent: int = 2, encoding: str = 'utf-8') -> bool:
        """Write Python object to JSON file"""
        try:
            Path(filename).parent.mkdir(parents=True, exist_ok=True)
            
            with open(filename, 'w', encoding=encoding) as file:
                json.dump(data, file, indent=indent, ensure_ascii=False)
            return True
        except Exception as e:
            print(f"Error writing JSON: {e}")
            return False
    def update_json(self, filename: str, updates: dict) -> bool:
        """Update specific keys in JSON file"""
        try:
            data = self.read_json(filename)
            if data is None:
                return False
            if isinstance(data, dict):
                data.update(updates)
                return self.write_json(filename, data)
            return False
        except Exception as e:
            print(f"Error updating JSON: {e}")
            return False
     def validate_json(self, filename: str) -> bool:
        """Validate JSON file format"""
        try:
            with open(filename, 'r', encoding='utf-8') as file:
                json.load(file)
            return True
        except json.JSONDecodeError:
            return False
        except Exception:
            return False
class XMLHandler:
    """XML file reading and writing utilities"""
    def read_xml(self, filename: str, encoding: str = 'utf-8') -> Optional[ET.Element]:
        """Read XML file and return root element"""
        try:
            tree = ET.parse(filename)
            return tree.getroot()
        except ET.ParseError as e:
            print(f"XML parse error: {e}")
            return None
        except Exception as e:
            print(f"Error reading XML: {e}")
            return None
    def write_xml(self, filename: str, root: ET.Element, encoding: str = 'utf-8') -> bool:
        """Write XML element to file"""
        try:
            Path(filename).parent.mkdir(parents=True, exist_ok=True)
            
            tree = ET.ElementTree(root)
            tree.write(filename, encoding=encoding, xml_declaration=True)
            return True
        except Exception as e:
            print(f"Error writing XML: {e}")
            return False
    def xml_to_dict(self, element: ET.Element) -> Dict[str, Any]:
        """Convert XML element to dictionary"""
        result = {}
        if element.attrib:
            result['@attributes'] = element.attrib
        if element.text and element.text.strip():
            result['text'] = element.text.strip()
        children = {}
        for child in element:
            child_dict = self.xml_to_dict(child)
            if child.tag in children:
                if not isinstance(children[child.tag], list):
                    children[child.tag] = [children[child.tag]]
                children[child.tag].append(child_dict)
            else:
                children[child.tag] = child_dict
        if children:
            result.update(children)
         return result
     def dict_to_xml(self, data: Dict[str, Any], root_tag: str = 'root') -> ET.Element:
        """Convert dictionary to XML element"""
        root = ET.Element(root_tag)
        self._dict_to_xml_recursive(data, root)
        return root
    def _dict_to_xml_recursive(self, data: Any, parent: ET.Element):
        """Recursively convert dictionary to XML"""
        if isinstance(data, dict):
            for key, value in data.items():
                if key == '@attributes':
                    parent.attrib.update(value)
                elif key == 'text':
                    parent.text = str(value)
                else:
                    child = ET.SubElement(parent, key)
                    self._dict_to_xml_recursive(value, child)
        elif isinstance(data, list):
            for item in data:
                self._dict_to_xml_recursive(item, parent)
        else:
            parent.text = str(data)
class ArchiveManager:
    """File compression and archiving utilities"""
     def create_zip(self, zip_filename: str, files_to_compress: List[str], 
                   base_path: str = None) -> bool:
        """Create ZIP archive from list of files"""
        try:
            with zipfile.ZipFile(zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:
                for file_path in files_to_compress:
                    if Path(file_path).exists():
                        arcname = Path(file_path).name
                        if base_path:
                            arcname = str(Path(file_path).relative_to(base_path))
                        zipf.write(file_path, arcname)
            return True
        except Exception as e:
            print(f"Error creating ZIP: {e}")
            return False
     def extract_zip(self, zip_filename: str, extract_to: str = ".") -> bool:
        """Extract ZIP archive"""
        try:
            with zipfile.ZipFile(zip_filename, 'r') as zipf:
                zipf.extractall(extract_to)
            return True
        except Exception as e:
            print(f"Error extracting ZIP: {e}")
            return False
     def list_zip_contents(self, zip_filename: str) -> List[str]:
        """List contents of ZIP archive"""
        try:
            with zipfile.ZipFile(zip_filename, 'r') as zipf:
                return zipf.namelist()
        except Exception as e:
            print(f"Error listing ZIP contents: {e}")
            return []
     def create_tar(self, tar_filename: str, files_to_compress: List[str], 
                   compression: str = 'gz', base_path: str = None) -> bool:
        """Create TAR archive with optional compression"""
        try:
            mode = f'w:{compression}' if compression else 'w'
            with tarfile.open(tar_filename, mode) as tar:
                for file_path in files_to_compress:
                    if Path(file_path).exists():
                        arcname = Path(file_path).name
                        if base_path:
                            arcname = str(Path(file_path).relative_to(base_path))
                        tar.add(file_path, arcname=arcname)
 return True
        except Exception as e:
            print(f"Error creating TAR: {e}")
            return False
    def extract_tar(self, tar_filename: str, extract_to: str = ".") -> bool:
        """Extract TAR archive"""
        try:
            with tarfile.open(tar_filename, 'r:*') as tar:
                tar.extractall(extract_to)
            return True
        except Exception as e:
            print(f"Error extracting TAR: {e}")
            return False
class FileSecurity:
    """File security and hashing utilities"""
    def calculate_file_hash(self, file_path: str, algorithm: str = 'sha256') -> str:
        """Calculate file hash"""
        try:
            hash_func = hashlib.new(algorithm)
            with open(file_path, 'rb') as file:
                for chunk in iter(lambda: file.read(4096), b""):
                    hash_func.update(chunk)
            return hash_func.hexdigest()
        except Exception as e:
            print(f"Error calculating hash: {e}")
            return ""
     def verify_file_integrity(self, file_path: str, expected_hash: str, 
                             algorithm: str = 'sha256') -> bool:
        """Verify file integrity using hash"""
        actual_hash = self.calculate_file_hash(file_path, algorithm)
        return actual_hash == expected_hash
    def find_duplicate_files(self, directory: str) -> Dict[str, List[str]]:
        """Find duplicate files based on hash"""
        hash_to_files = defaultdict(list)
        try:
            for file_path in Path(directory).rglob("*"):
                if file_path.is_file():
                    file_hash = self.calculate_file_hash(str(file_path))
                    hash_to_files[file_hash].append(str(file_path))
        except Exception as e:
            print(f"Error finding duplicates: {e}")
        return {hash_val: files for hash_val, files in hash_to_files.items() if len(files) > 1}
class BatchFileProcessor:
    """Process multiple files in batches"""
    def __init__(self, batch_size: int = 10):
        self.batch_size = batch_size
        self.processed_files = []
        self.failed_files = []
    def process_files(self, file_list: List[str], processor_func) -> Dict[str, Any]:
        """Process files in batches"""
        results = {
            'processed': 0,
            'failed': 0,
            'total': len(file_list)
        }
        for i in range(0, len(file_list), self.batch_size):
            batch = file_list[i:i + self.batch_size]
            print(f"Processing batch {i//self.batch_size + 1}: {len(batch)} files")
         for file_path in batch:
                try:
                    result = processor_func(file_path)
                    self.processed_files.append(file_path)
                    results['processed'] += 1
                except Exception as e:
                    print(f"Error processing {file_path}: {e}")
                    self.failed_files.append(file_path)
                    results['failed'] += 1
        return results
   def get_processing_summary(self) -> Dict[str, Any]:
        """Get summary of processing results"""
        total = len(self.processed_files) + len(self.failed_files)
        return {
            'processed_files': self.processed_files,
            'failed_files': self.failed_files,
            'success_rate': len(self.processed_files) / total * 100 if total > 0 else 0
        }
def test_exercises():
    """Test all exercises"""
    print("Testing Module 9 Exercises...")
    print("\n1. Testing File Operations:")
    file_ops = FileOperations()
    test_content = "Hello, World!\nThis is a test file.\nLine 3"
    file_ops.write_text_file("test_file.txt", test_content)
    content = file_ops.read_text_file("test_file.txt")
    print(f"File content: {content}")
    lines = file_ops.read_lines("test_file.txt")
    print(f"File lines: {lines}")
    print("\n2. Testing File System Manager:")
    fs_manager = FileSystemManager()
    fs_manager.create_directory("test_dir")
    file_info = fs_manager.get_file_info("test_file.txt")
    print(f"File info: {file_info}")
    print("\n3. Testing CSV Handler:")
    csv_handler = CSVHandler()
    test_data = [
        {"name": "Alice", "age": 30, "city": "New York"},
        {"name": "Bob", "age": 25, "city": "Los Angeles"},
        {"name": "Charlie", "age": 35, "city": "Chicago"}
    ]
    csv_handler.write_csv("test_data.csv", test_data)
    csv_data = csv_handler.read_csv("test_data.csv")
    print(f"CSV data: {csv_data}")
    print("\n4. Testing JSON Handler:")
    json_handler = JSONHandler()
    test_json = {
        "users": [
            {"name": "Alice", "age": 30},
            {"name": "Bob", "age": 25}
        ],
        "settings": {
            "theme": "dark",
            "language": "en"
        }
    }
    json_handler.write_json("test_data.json", test_json)
    json_data = json_handler.read_json("test_data.json")
    print(f"JSON data: {json_data}")
    print("\n5. Testing XML Handler:")
    xml_handler = XMLHandler()
    root = ET.Element("users")
    for user in test_json["users"]:
        user_elem = ET.SubElement(root, "user")
        name_elem = ET.SubElement(user_elem, "name")
        name_elem.text = user["name"]
        age_elem = ET.SubElement(user_elem, "age")
        age_elem.text = str(user["age"])
    xml_handler.write_xml("test_data.xml", root)
    xml_data = xml_handler.read_xml("test_data.xml")
    if xml_data is not None:
        print(f"XML root tag: {xml_data.tag}")
    print("\n6. Testing Archive Manager:")
    archive_manager = ArchiveManager()
    files_to_compress = ["test_file.txt", "test_data.csv", "test_data.json"]
    archive_manager.create_zip("test_archive.zip", files_to_compress)
    zip_contents = archive_manager.list_zip_contents("test_archive.zip")
    print(f"ZIP contents: {zip_contents}")
    print("\n7. Testing File Security:")
    file_security = FileSecurity()
    file_hash = file_security.calculate_file_hash("test_file.txt")
    print(f"File hash: {file_hash}")
    print("\n8. Testing Batch Processing:")
    batch_processor = BatchFileProcessor(batch_size=2)
    def simple_processor(file_path):
        """Simple file processor"""
        return f"Processed: {file_path}"
    results = batch_processor.process_files(files_to_compress, simple_processor)
    print(f"Batch processing results: {results}")
    print("\nCleaning up test files...")
    for file_path in files_to_compress + ["test_archive.zip", "test_data.xml"]:
        file_ops.delete_file(file_path)
     fs_manager.delete_directory("test_dir")
     print("\nAll exercises completed!")
if __name__ == "__main__":
    test_exercises()
Testing Module 9 Exercises...

1. Testing File Operations:
Permission denied to write test_file.txt
File test_file.txt not found
File content:
Error reading lines from test_file.txt: [Errno 2] No such file or directory: 'test_file.txt'
File lines: []

2. Testing File System Manager:
Error creating directory: [WinError 5] Access is denied: 'test_dir'
File info: {}

3. Testing CSV Handler:
Error writing CSV: [Errno 13] Permission denied: 'test_data.csv'
Error reading CSV: [Errno 2] No such file or directory: 'test_data.csv'
CSV data: []

4. Testing JSON Handler:
Error writing JSON: [Errno 13] Permission denied: 'test_data.json'
File test_data.json not found
JSON data: None

5. Testing XML Handler:
Error writing XML: [Errno 13] Permission denied: 'test_data.xml'
Error reading XML: [Errno 2] No such file or directory: 'test_data.xml'

6. Testing Archive Manager:
Error creating ZIP: [Errno 13] Permission denied: 'test_archive.zip'
Error listing ZIP contents: [Errno 2] No such file or directory: 'test_archive.zip'
ZIP contents: []

7. Testing File Security:
Error calculating hash: [Errno 2] No such file or directory: 'test_file.txt'
File hash:

8. Testing Batch Processing:
Processing batch 1: 2 files
Processing batch 2: 1 files
Batch processing results: {'processed': 3, 'failed': 0, 'total': 3}

Cleaning up test files...

All exercises completed!